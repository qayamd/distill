seed: 42
device: "cuda"
subset_size: 1000
max_tokens_per_batch: 4096
max_batch_size: 16
n_positions: 2048
n_experts: 8192
n_heads: 16
top_k: 16
d_key: 64
share_params: true
learning_rate: 1e-5
warmup_steps: 5000
max_steps: 200000
grad_clip: 0.5
weight_decay: 0.01
use_mixed_precision: true
temperature: 2.0
layer_wise_loss_weight: 0.1
gradient_accumulation_steps: 4
datasets:
  - numina_cot
  - gsm8k
num_epochs:
  numina_cot: 10
  gsm8k: 2
checkpoint_dir: './checkpoints'
log_dir: './logs'
tokenizer_path: './tokenizer.json'
tokenizer_config_path: './tokenizer_config.json'
teacher_model:
  files:
    - "./model-00001-of-00003.safetensors"
    - "./model-00002-of-00003.safetensors"
    - "./model-00003-of-00003.safetensors"
dataloader:
  num_workers: 4
  pin_memory: true
logging:
  level: "INFO"
  log_to_file: true
  log_file: "training.log"
